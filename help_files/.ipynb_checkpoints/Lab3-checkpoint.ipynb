{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Poker+Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "# read the data in and add column names\n",
    "data_train = pd.read_csv(\"poker.txt\", header=None,\n",
    "                        names=['S1', 'C1', 'S2', 'C2', 'S3', 'C3','S4', 'C4', 'S5', 'C5', 'CLASS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=data_train[['S1', 'C1', 'S2', 'C2', 'S3', 'C3','S4', 'C4', 'S5', 'C5']] # get train data\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standarize the data (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# standardize clustering variables to have mean=0 and sd=1 so that card suit and\n",
    "# rank are on the same scale as to have the variables equally contribute to the analysis\n",
    "clustervar=cluster.copy() # create a copy -> best practice\n",
    "\n",
    "clustervar['S1']=preprocessing.scale(clustervar['S1'].astype('float64'))\n",
    "clustervar['C1']=preprocessing.scale(clustervar['C1'].astype('float64'))\n",
    "clustervar['S2']=preprocessing.scale(clustervar['S2'].astype('float64'))\n",
    "clustervar['C2']=preprocessing.scale(clustervar['C2'].astype('float64'))\n",
    "clustervar['S3']=preprocessing.scale(clustervar['S3'].astype('float64'))\n",
    "clustervar['C3']=preprocessing.scale(clustervar['C3'].astype('float64'))\n",
    "clustervar['S4']=preprocessing.scale(clustervar['S4'].astype('float64'))\n",
    "clustervar['C4']=preprocessing.scale(clustervar['C4'].astype('float64'))\n",
    "clustervar['S5']=preprocessing.scale(clustervar['S5'].astype('float64'))\n",
    "clustervar['C5']=preprocessing.scale(clustervar['C5'].astype('float64'))\n",
    "\n",
    "clus_train = clustervar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3, init='random', random_state=22) # init = how to select the first cent, Lernverfahren\n",
    "    \n",
    "model.fit(clus_train) # learn on training data \n",
    "    \n",
    "clusassign = model.predict(clus_train) # get cluster assignment\n",
    "    \n",
    "print(clusassign[:30]) # cluster of first 30 rows\n",
    "# print(data_train[:30])\n",
    "model.labels_[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusassign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "score = metrics.silhouette_score(clus_train, model.labels_, sample_size=1000)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA # PCA from sklearn package\n",
    "\n",
    "pca_2 = PCA(2) # return 2 first canonical variables > want to reduce to 2 dimensions (in this example from 10)\n",
    "plot_columns = pca_2.fit_transform(clus_train) # fit PCA to the train dataset\n",
    "plot_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=model.labels_,) # plot 1st canonical variable on x axis, 2nd on y-axis\n",
    "plt.xlabel('Canonical variable 1') # pc1, canonical = transformed\n",
    "plt.ylabel('Canonical variable 2') #pc2\n",
    "plt.title('Scatterplot of Canonical Variables for 2 Clusters')\n",
    "plt.show() \n",
    "# a color per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=model.labels_, alpha=0.25) # plot 1st canonical variable on x axis, 2nd on y-axis\n",
    "plt.xlabel('Canonical variable 1') # pc1, canonical = transformed\n",
    "plt.ylabel('Canonical variable 2') #pc2\n",
    "plt.title('Scatterplot of Canonical Variables for 2 Clusters')\n",
    "plt.show() \n",
    "# a color per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "Assignment is in this area <br>\n",
    "further info: https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000,\n",
    "                                   stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open('politics.txt','r') as pfh, open('sports.txt','r') as sfh:\n",
    "    politics = pfh.read()\n",
    "    sports = sfh.read()\n",
    "pfh.close()\n",
    "sfh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [politics,sports]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf transformation\n",
    "tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "tfidf.data[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=5, # LDA, n_components = number of topics to be found\n",
    "                                learning_method='online', # \n",
    "                                learning_offset=50., \n",
    "                                random_state=0) # set seed\n",
    "                                # doc_topic_prior = alpha = 0.01 per default\n",
    "                                # topic_word_prior = beta\n",
    "\n",
    "lda.fit(tfidf)\n",
    "\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every value above is connected to a word below (e. g. 0.9064... to '10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print(tfidf_feature_names[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print out top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x =[3,5,7,1,0,9,20,5,13,6]\n",
    "a = np.argsort(x) # for getting the top words later on\n",
    "print(a)  # returns index with lowest number first, e. g. index 4 contains number 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[:-3 : -1]) # last two values, first two descending values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_words = [tfidf_feature_names[i] for i in topic.argsort()[:-10-1:-1]] # -10 = last 10 values & \n",
    "    print('Topic:',topic_idx,'--',top_words) # -1 because python starts at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate based on perplexity (Ratlosigkeit, Verwirrung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscores = []\n",
    "for n_topic in [5,10,15,20,30]:\n",
    "    lda = LatentDirichletAllocation(n_components=n_topic, max_iter=5,random_state=7)\n",
    "\n",
    "    lda.fit(tfidf)\n",
    "\n",
    "    perplexity_score = lda.perplexity(tfidf)\n",
    "    print(perplexity_score)\n",
    "    pscores.append(perplexity_score)\n",
    "\n",
    "# pscores\n",
    "# perplexity score of 0 is best value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot the perplexity score with n_topics\n",
    "plt.plot([5,10,15,20,30],pscores,'r+--')\n",
    "plt.xlabel('# of topics')\n",
    "plt.ylabel('Perplexity score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: le245 = 10^245\n",
    "\n",
    "**Intepretation: up to 20 topics are reasonable, but no more!**\n",
    "\n",
    "Practical tipps:\n",
    "- use this for less than 10'000 documents: https://pypi.org/project/lda/\n",
    "- use if there are over 10'000 document: https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
