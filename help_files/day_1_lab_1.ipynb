{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further informations: http://www.nltk.org/book/ch03.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_en = stopwords.words('english')\n",
    "stops_ge = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'st.gallen']\n",
      "['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', 'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', 'die', 'das', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', 'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', 'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', 'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', 'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', 'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', 'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', 'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', 'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', 'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', 'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', 'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', 'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', 'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', 'zwischen']\n"
     ]
    }
   ],
   "source": [
    "stops_en.append('st.gallen')\n",
    "print(stops_en)\n",
    "print(stops_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 231\n"
     ]
    }
   ],
   "source": [
    "print(len(stops_en), len(stops_ge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentence tokenization and word tokenziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_gallen = '''The town of St. Gallen grew around the Abbey of St Gall, founded in the 8th century.\n",
    "The abbey is said to have been built at the site of the hermitage of Irish missionary Gallus, \n",
    "who according to legend had established himself by the river Steinach in AD 612. \n",
    "The monastery itself was founded by Saint Othmar in c. 720. \n",
    "The abbey prospered in the 9th century and became a site of pilgrimage and a center of trade, \n",
    "with associated guest houses, stables and other facilities, a hospital, one of the first monastery schools\n",
    "north of the Alps. By the tenth century, a settlement had grown up around the abbey. \n",
    "In 926 Magyar raiders attacked the abbey and surrounding town. \n",
    "Saint Wiborada, the first woman formally canonized by the Vatican, reportedly saw a vision\n",
    "of the impending attack and warned the monks and citizens to flee.\n",
    "While the monks and the abbey treasure escaped, Wiborada chose to stay behind and was killed by the raiders.\n",
    "Between 924 and 933 the Magyars again threatened the abbey, and its books were removed for safekeeping to Reichenau.\n",
    "Not all the books were returned.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The town of St. Gallen grew around the Abbey of St Gall, founded in the 8th century.\n",
      "The abbey is said to have been built at the site of the hermitage of Irish missionary Gallus, \n",
      "who according to legend had established himself by the river Steinach in AD 612.\n",
      "The monastery itself was founded by Saint Othmar in c. 720.\n",
      "The abbey prospered in the 9th century and became a site of pilgrimage and a center of trade, \n",
      "with associated guest houses, stables and other facilities, a hospital, one of the first monastery schools\n",
      "north of the Alps.\n",
      "By the tenth century, a settlement had grown up around the abbey.\n",
      "In 926 Magyar raiders attacked the abbey and surrounding town.\n",
      "Saint Wiborada, the first woman formally canonized by the Vatican, reportedly saw a vision\n",
      "of the impending attack and warned the monks and citizens to flee.\n",
      "While the monks and the abbey treasure escaped, Wiborada chose to stay behind and was killed by the raiders.\n",
      "Between 924 and 933 the Magyars again threatened the abbey, and its books were removed for safekeeping to Reichenau.\n",
      "Not all the books were returned.\n"
     ]
    }
   ],
   "source": [
    "# separate sentences in own units\n",
    "for sent in sent_tokenize(st_gallen):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The town of St. Gallen grew around the Abbey of St Gall, founded in the 8th century.', 'The abbey is said to have been built at the site of the hermitage of Irish missionary Gallus, \\nwho according to legend had established himself by the river Steinach in AD 612.', 'The monastery itself was founded by Saint Othmar in c. 720.', 'The abbey prospered in the 9th century and became a site of pilgrimage and a center of trade, \\nwith associated guest houses, stables and other facilities, a hospital, one of the first monastery schools\\nnorth of the Alps.', 'By the tenth century, a settlement had grown up around the abbey.', 'In 926 Magyar raiders attacked the abbey and surrounding town.', 'Saint Wiborada, the first woman formally canonized by the Vatican, reportedly saw a vision\\nof the impending attack and warned the monks and citizens to flee.', 'While the monks and the abbey treasure escaped, Wiborada chose to stay behind and was killed by the raiders.', 'Between 924 and 933 the Magyars again threatened the abbey, and its books were removed for safekeeping to Reichenau.', 'Not all the books were returned.']\n",
      "Count of sentences: 10\n"
     ]
    }
   ],
   "source": [
    "# get each own sentence in a list\n",
    "x = sent_tokenize(st_gallen)\n",
    "print(x)\n",
    "\n",
    "print(\"Count of sentences: \" + str(len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert text into NLTK Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The = stop word...\n",
      "town\n",
      "of = stop word...\n",
      "St.\n",
      "Gallen\n",
      "grew\n",
      "around\n",
      "the = stop word...\n",
      "Abbey\n",
      "of = stop word...\n",
      "St\n",
      "Gall\n",
      ",\n",
      "founded\n",
      "in = stop word...\n",
      "the = stop word...\n",
      "8th\n",
      "century\n",
      ".\n",
      "['The', 'town', 'of', 'St.', 'Gallen', 'grew', 'around', 'the', 'Abbey', 'of', 'St', 'Gall', ',', 'founded', 'in', 'the', '8th', 'century', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize to words = each word = one list entry\n",
    "sent = 'The town of St. Gallen grew around the Abbey of St Gall, founded in the 8th century.'\n",
    "words = word_tokenize(sent)\n",
    "for word in words:\n",
    "    if word.lower() in stops_en:\n",
    "        print(word, '=', 'stop word...')\n",
    "    else:\n",
    "        print(word)\n",
    "print(words)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: The town of St. Gallen grew around the...>\n",
      "<FreqDist with 17 samples and 19 outcomes>\n",
      "[('of', 2), ('the', 2), ('The', 1)]\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(words)\n",
    "print(text)\n",
    "dist = nltk.FreqDist(text)\n",
    "print(dist)\n",
    "# show words with most counts\n",
    "print(dist.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = unique words & outcomes = all single words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 8] nodename nor servname provided, or not\n",
      "[nltk_data]     known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOWN\n",
      "GALLEN\n",
      "GREW\n",
      "AROUND\n",
      "ABBEY\n",
      "GALL\n",
      "FOUNDED\n",
      "CENTURY\n",
      "['TOWN', 'GALLEN', 'GREW', 'AROUND', 'ABBEY', 'GALL', 'FOUNDED', 'CENTURY']\n",
      "[('The', 'DT'), ('town', 'NN'), ('of', 'IN'), ('St.', 'NNP'), ('Gallen', 'NNP'), ('grew', 'VBD'), ('around', 'RP'), ('the', 'DT'), ('Abbey', 'NNP'), ('of', 'IN'), ('St', 'NNP'), ('Gall', 'NNP'), (',', ','), ('founded', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('8th', 'JJ'), ('century', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sent) # convert sentence into word list\n",
    "new_word_list = [] # this list is to store words with upper cases\n",
    "for w in words:\n",
    "    if len(w) <= 3:\n",
    "        continue\n",
    "    new_word = w.upper()\n",
    "    print(new_word)\n",
    "    new_word_list.append(new_word)\n",
    "\n",
    "print(new_word_list)\n",
    "    \n",
    "tagged = list(pos_tag(word_tokenize(sent)))\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code meaning:\n",
    "- CC coordinating conjunction\n",
    "- CD cardinal digit\n",
    "- DT determiner\n",
    "- EX existential there (like: “there is” … think of it like “there exists”)\n",
    "- FW foreign word\n",
    "- IN preposition/subordinating conjunction\n",
    "- JJ adjective ‘big’\n",
    "- JJR adjective, comparative ‘bigger’\n",
    "- JJS adjective, superlative ‘biggest’\n",
    "- LS list marker 1)\n",
    "- MD modal could, will\n",
    "- NN noun, singular ‘desk’\n",
    "- NNS noun plural ‘desks’\n",
    "- NNP proper noun, singular ‘Harrison’\n",
    "- NNPS proper noun, plural ‘Americans’\n",
    "- PDT predeterminer ‘all the kids’\n",
    "- POS possessive ending parent’s\n",
    "- PRP personal pronoun I, he, she\n",
    "- PRP possessive pronoun my, his, hers\n",
    "- RB adverb very, silently,\n",
    "- RBR adverb, comparative better\n",
    "- RBS adverb, superlative best\n",
    "- RP particle give up\n",
    "- TO, to go ‘to’ the store.\n",
    "- UH interjection, errrrrrrrm\n",
    "- VB verb, base form take\n",
    "- VBD verb, past tense took\n",
    "- VBG verb, gerund/present participle taking\n",
    "- VBN verb, past participle taken\n",
    "- VBP verb, sing. present, non-3d take\n",
    "- VBZ verb, 3rd person sing. present takes\n",
    "- WDT wh-determiner which\n",
    "- WP wh-pronoun who, what\n",
    "- WP possessive wh-pronoun whose\n",
    "- WRB wh-abverb where, when\n",
    "\n",
    "accuracy is about 90% \n",
    "\n",
    "Details: https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('town', 'NN')\n",
      "('century', 'NN')\n"
     ]
    }
   ],
   "source": [
    "# just get nouns\n",
    "tagged = list(pos_tag(word_tokenize(sent)))\n",
    "for tag in tagged:\n",
    "    if len(tag[0]) <= 3:\n",
    "        continue # do nothing\n",
    "    if tag[1] == 'NN':\n",
    "        print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('town', 'NN')\n",
      "('Gallen', 'NNP')\n",
      "('Abbey', 'NNP')\n",
      "('Gall', 'NNP')\n",
      "('century', 'NN')\n"
     ]
    }
   ],
   "source": [
    "# just get nouns\n",
    "tagged = list(pos_tag(word_tokenize(sent)))\n",
    "for element in tagged:\n",
    "    if len(element[0]) <= 3:\n",
    "        continue # do nothing\n",
    "    if re.findall('NN.*', element[1]): # regex, .* means one character 0 to multiple times\n",
    "        print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: | porter: | lancaster:\n",
      "<class 'str'>\n",
      "The | the | the\n",
      "<class 'str'>\n",
      "town | town | town\n",
      "<class 'str'>\n",
      "of | of | of\n",
      "<class 'str'>\n",
      "St. | st. | st.\n",
      "<class 'str'>\n",
      "Gallen | gallen | gal\n",
      "<class 'str'>\n",
      "grew | grew | grew\n",
      "<class 'str'>\n",
      "around | around | around\n",
      "<class 'str'>\n",
      "the | the | the\n",
      "<class 'str'>\n",
      "Abbey | abbey | abbey\n",
      "<class 'str'>\n",
      "of | of | of\n",
      "<class 'str'>\n",
      "St | St | st\n",
      "<class 'str'>\n",
      "Gall | gall | gal\n",
      "<class 'str'>\n",
      ", | , | ,\n",
      "<class 'str'>\n",
      "founded | found | found\n",
      "<class 'str'>\n",
      "in | in | in\n",
      "<class 'str'>\n",
      "the | the | the\n",
      "<class 'str'>\n",
      "8th | 8th | 8th\n",
      "<class 'str'>\n",
      "century | centuri | century\n",
      "<class 'str'>\n",
      ". | . | .\n"
     ]
    }
   ],
   "source": [
    "# use two different stemming methods and compare the results\n",
    "portar = nltk.PorterStemmer() # is best practise\n",
    "\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "print('original: |', 'porter: |', 'lancaster:' )\n",
    "for t in word_tokenize(sent): # word_tokenize gets a list of words\n",
    "    print(type(t))\n",
    "    print(t, '|', portar.stem(t), '|', lancaster.stem(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "Remove unnessesary characters (white spaces, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "for t in word_tokenize(sent):\n",
    "    print(t, ',', wnl.lemmatize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Sense Disambiguation\n",
    "get the contextual meaning of several same words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "sent = ['I', 'went', 'to', 'the', 'bank', 'to', 'deposit', 'money', '.']\n",
    "print(lesk(sent, 'bank')) # get the most suitable contextual meaning for word bank for the sentence above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all definitions of word bank\n",
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('bank'):\n",
    "    print(ss, ss.definition())\n",
    "    \n",
    "# there is a supervised machine learning algorithm which predicts the best suitable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all definitions of word tea\n",
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('tea'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices, in one of the most aggressive regulatory actions against American technology giants and one that may force lasting changes to smartphones.'\n",
    "ne_tree = nltk.ne_chunk(pos_tag(word_tokenize(ex)))\n",
    "print(ne_tree)\n",
    "# First column = entity\n",
    "# second column = original word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "- geo = Geographical Entity\n",
    "- org = Organization\n",
    "- per = Person\n",
    "- gpe = Geopolitical Entity\n",
    "- tim = Time indicator\n",
    "- art = Artifact\n",
    "- eve = Event\n",
    "- nat = Natural Phenomenon\n",
    "\n",
    "https://nlpforhackers.io/named-entity-extraction/\n",
    "\n",
    "https://www.nltk.org/book/ch07.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
